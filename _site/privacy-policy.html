<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Privacy Policy | UCL AI Centre Posts</title>

    <!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Privacy Policy | UCL AI Centre Posts</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Privacy Policy" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="UCL AI Centre" />
<meta property="og:description" content="UCL AI Centre" />
<link rel="canonical" href="http://localhost:4000/privacy-policy.html" />
<meta property="og:url" content="http://localhost:4000/privacy-policy.html" />
<meta property="og:site_name" content="UCL AI Centre Posts" />
<script type="application/ld+json">
{"@type":"WebPage","url":"http://localhost:4000/privacy-policy.html","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.png"}},"headline":"Privacy Policy","description":"UCL AI Centre","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="shortcut icon" type="image/x-icon" href="/assets/images/favicon.ico">

    <!-- Font Awesome Icons -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">

    <!-- Google Fonts-->
    <link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">

    <!-- Bootstrap Modified -->
    <link rel="stylesheet" href="/assets/css/main.css">

    <!-- Theme Stylesheet -->
    <link rel="stylesheet" href="/assets/css/theme.css">

    <!-- Jquery on header to make sure everything works, the rest  of the scripts in footer for fast loading -->
    <script
    src="https://code.jquery.com/jquery-3.3.1.min.js"
    integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
    crossorigin="anonymous"></script>

    <!-- This goes before </head> closing tag, Google Analytics can be placed here --> 


</head>

<body class="">

    <!-- Navbar -->
    <nav id="MagicMenu" class="topnav navbar navbar-expand-lg navbar-light bg-white fixed-top">
    <div class="container">
     <a class="navbar-brand" href="/index.html"><strong>UCL AI Centre Posts</strong></a>
        <button class="navbar-toggler collapsed" type="button" data-toggle="collapse" data-target="#navbarColor02" aria-controls="navbarColor02" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
        </button>
        <div class="navbar-collapse collapse" id="navbarColor02" style="">
            <ul class="navbar-nav mr-auto d-flex align-items-center">
               <!--  Replace menu links here -->

<!--<li class="nav-item">
<a class="nav-link" href="/index.html">Home</a>
</li>-->
<li class="nav-item">
<a class="nav-link" href="/authors-list.html">Authors</a>
</li>
<li class="nav-item">
<a class="nav-link" href="https://www.ucl.ac.uk/ai-centre">AI Centre Main Site</a>
</li>

<!--
<li class="nav-item">
<a class="nav-link" href="/contact.html">Contact</a>
</li>-->


            </ul>
            <ul class="navbar-nav ml-auto d-flex align-items-center">
                <script src="/assets/js/lunr.js"></script>

<script>
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 1000 );
        $( "body" ).removeClass( "modal-open" );
    });
});
    

var documents = [{
    "id": 0,
    "url": "http://localhost:4000/404/",
    "title": "",
    "body": " 404 Page not found :(  The requested page could not be found. "
    }, {
    "id": 1,
    "url": "http://localhost:4000/about.html",
    "title": "About",
    "body": "Made with by Sal @wowthemesnet. "
    }, {
    "id": 2,
    "url": "http://localhost:4000/author-admin.html",
    "title": "Admin",
    "body": "                        Admin Follow:                 UCL admin team                                   Posts by Admin:                   		UCL AI Centre	: 		  The AI Centre carries out foundational research in AI. As we transition to a more automated society, the core aim of the Centre is to create new AI technologies and advise on the use . . . 	 			In 				University College London, 								Jan 18, 2019						        "
    }, {
    "id": 3,
    "url": "http://localhost:4000/author-davidbarber.html",
    "title": "David Barber",
    "body": "                        David Barber Follow:         http://web4. cs. ucl. ac. uk/staff/D. Barber/pmwiki/pmwiki. php         David is the Director of the UCL Centre for Artificial Intelligence                                   Posts by David Barber:                   		Training Models that have Zero Likelihood	: 		  A popular class of models in machine learning is the so-called generative model class with deterministic outputs. These are currently heavily used for example the generation of realis. . . 	 			In 				Optimization, 								Dec 21, 2019						            		Learning From Scratch by Thinking Fast and Slow with Deep Learning and Tree Search	: 		  According to dual process theory human reasoning consists of two different kinds of thinking. System 1 is a fast, unconscious and automatic mode of thought, also known as intuition. Sy. . . 	 			In 				Reinforcement Learning, 								Nov 07, 2017						            		Some modest insights into the error surface of Neural Nets	: 		  Did you know that feedforward Neural Nets (with piecewise linear transfer functions) have no smooth local maxima?In our recent ICML paper Practical Gauss-Newton Optimisation for Deep . . . 	 			In 				Optimization, 								Jul 30, 2017						            		Evolutionary Optimization as a Variational Method	: 		  Variational Optimization is based on the boundThat is, the minimum of a collection of values is always less than their average.  By defininginstead of minimising with respect to , we. . . 	 			In 				Optimization, 								Apr 03, 2017						            		Training with a large number of classes	: 		  In machine learning we often face the issue of a very large number of classes in a classification problem. This causes a bottleneck in the computation. There’s though a simple and eff. . . 	 			In 				Classification, 								Mar 15, 2017						        "
    }, {
    "id": 4,
    "url": "http://localhost:4000/author-harshil.html",
    "title": "Harshil Shah",
    "body": "                        Harshil Shah Follow:                 Harshil Shah is a PhD student at the UCL AI Centre                                   Posts by Harshil Shah:                   		Generative Neural Machine Translation	: 		  What’s wrong with current Machine Translation models?Machine Learning models are still largely superficial – the models don’t really ‘understand’ the meaning of the sentences they are. . . 	 			In 				Natural Language Processing, 								Sep 12, 2018						        "
    }, {
    "id": 5,
    "url": "http://localhost:4000/author-sal.html",
    "title": "Sal",
    "body": "                        Sal Follow:                                                    Posts by Sal:               "
    }, {
    "id": 6,
    "url": "http://localhost:4000/authors-list.html",
    "title": "Authors",
    "body": "Authors:                                             davidbarber :       (View Posts)      David is the Director of the UCL Centre for Artificial Intelligence                          &nbsp;       &nbsp;                                                                             admin :       (View Posts)      UCL admin team                          &nbsp;       &nbsp;                                                                             harshil :       (View Posts)      Harshil Shah is a PhD student at the UCL AI Centre                          &nbsp;       &nbsp;                                      "
    }, {
    "id": 7,
    "url": "http://localhost:4000/categories.html",
    "title": "Categories",
    "body": "          Categories               Classification:                                  		Training with a large number of classes	: 		  In machine learning we often face the issue of a very large number of classes in a classification problem. This causes a bottleneck in the computation. There’s though a simple and eff. . . 	 			In 				Classification, 								Mar 15, 2017						                              Optimization:                                  		Training Models that have Zero Likelihood	: 		  A popular class of models in machine learning is the so-called generative model class with deterministic outputs. These are currently heavily used for example the generation of realis. . . 	 			In 				Optimization, 								Dec 21, 2019						                                 		Some modest insights into the error surface of Neural Nets	: 		  Did you know that feedforward Neural Nets (with piecewise linear transfer functions) have no smooth local maxima?In our recent ICML paper Practical Gauss-Newton Optimisation for Deep . . . 	 			In 				Optimization, 								Jul 30, 2017						                                 		Evolutionary Optimization as a Variational Method	: 		  Variational Optimization is based on the boundThat is, the minimum of a collection of values is always less than their average.  By defininginstead of minimising with respect to , we. . . 	 			In 				Optimization, 								Apr 03, 2017						                              Reinforcement Learning:                                  		Learning From Scratch by Thinking Fast and Slow with Deep Learning and Tree Search	: 		  According to dual process theory human reasoning consists of two different kinds of thinking. System 1 is a fast, unconscious and automatic mode of thought, also known as intuition. Sy. . . 	 			In 				Reinforcement Learning, 								Nov 07, 2017						                              Natural Language Processing:                                  		Generative Neural Machine Translation	: 		  What’s wrong with current Machine Translation models?Machine Learning models are still largely superficial – the models don’t really ‘understand’ the meaning of the sentences they are. . . 	 			In 				Natural Language Processing, 								Sep 12, 2018						                              University College London:                                  		UCL AI Centre	: 		  The AI Centre carries out foundational research in AI. As we transition to a more automated society, the core aim of the Centre is to create new AI technologies and advise on the use . . . 	 			In 				University College London, 								Jan 18, 2019						                                             Featured:    				                                          Training Models that have Zero Likelihood                          In                     Optimization,                                                                                           Learning From Scratch by Thinking Fast and Slow with Deep Learning and Tree Search                          In                     Reinforcement Learning,                                                                                           Some modest insights into the error surface of Neural Nets                          In                     Optimization,                                                                                           Evolutionary Optimization as a Variational Method                          In                     Optimization,                                                                                           Training with a large number of classes                          In                     Classification,                                                                   "
    }, {
    "id": 8,
    "url": "http://localhost:4000/contact.html",
    "title": "Contact",
    "body": "  Please send your message to UCL AI Centre Posts. We will reply as soon as possible!   "
    }, {
    "id": 9,
    "url": "http://localhost:4000/",
    "title": "UCL AI Centre",
    "body": "                                  Training Models that have Zero Likelihood  :       A popular class of models in machine learning is the so-called generative model class with deterministic outputs. These are currently. . .               In                 Optimization,                                        Dec 21, 2019                                                                                                                             UCL AI Centre          :                       In                         University College London,                                                                  Jan 18, 2019                                                                                                                                     Generative Neural Machine Translation          :                       In                         Natural Language Processing,                                                                  Sep 12, 2018                                                                                                                                    Learning From Scratch by Thinking Fast and Slow with Deep Learning and Tree Search          :                       In                         Reinforcement Learning,                                                                  Nov 07, 2017                                                       UCL AI Centre                  The AI Centre carries out foundational research in AI. As we transition to a more automated society, the core aim of the Centre is to. . .                 Read More            	                                 All Stories:                   		Training Models that have Zero Likelihood	: 		  A popular class of models in machine learning is the so-called generative model class with deterministic outputs. These are currently heavily used for example the generation of realis. . . 	 			In 				Optimization, 								Dec 21, 2019						                  		UCL AI Centre	: 		  The AI Centre carries out foundational research in AI. As we transition to a more automated society, the core aim of the Centre is to create new AI technologies and advise on the use . . . 	 			In 				University College London, 								Jan 18, 2019						                  		Generative Neural Machine Translation	: 		  What’s wrong with current Machine Translation models?Machine Learning models are still largely superficial – the models don’t really ‘understand’ the meaning of the sentences they are. . . 	 			In 				Natural Language Processing, 								Sep 12, 2018						                  		Learning From Scratch by Thinking Fast and Slow with Deep Learning and Tree Search	: 		  According to dual process theory human reasoning consists of two different kinds of thinking. System 1 is a fast, unconscious and automatic mode of thought, also known as intuition. Sy. . . 	 			In 				Reinforcement Learning, 								Nov 07, 2017						                  		Some modest insights into the error surface of Neural Nets	: 		  Did you know that feedforward Neural Nets (with piecewise linear transfer functions) have no smooth local maxima?In our recent ICML paper Practical Gauss-Newton Optimisation for Deep . . . 	 			In 				Optimization, 								Jul 30, 2017						                  		Evolutionary Optimization as a Variational Method	: 		  Variational Optimization is based on the boundThat is, the minimum of a collection of values is always less than their average.  By defininginstead of minimising with respect to , we. . . 	 			In 				Optimization, 								Apr 03, 2017						                  		Training with a large number of classes	: 		  In machine learning we often face the issue of a very large number of classes in a classification problem. This causes a bottleneck in the computation. There’s though a simple and eff. . . 	 			In 				Classification, 								Mar 15, 2017						                                                  Featured:    				                                          Training Models that have Zero Likelihood                          In                     Optimization,                                                                                           Learning From Scratch by Thinking Fast and Slow with Deep Learning and Tree Search                          In                     Reinforcement Learning,                                                                                           Some modest insights into the error surface of Neural Nets                          In                     Optimization,                                                                                           Evolutionary Optimization as a Variational Method                          In                     Optimization,                                                                                           Training with a large number of classes                          In                     Classification,                                                               "
    }, {
    "id": 10,
    "url": "http://localhost:4000/privacy-policy.html",
    "title": "Privacy Policy",
    "body": "“UCL AI Centre Posts” takes your privacy seriously. To better protect your privacy we provide this privacy policy notice explaining the way your personal information is collected and used. Collection of Routine Information: This website track basic information about their visitors. This information includes, but is not limited to, IP addresses, browser details, timestamps and referring pages. None of this information can personally identify specific visitor to this website. The information is tracked for routine administration and maintenance purposes. Cookies: Where necessary, this website uses cookies to store information about a visitor’s preferences and history in order to better serve the visitor and/or present the visitor with customized content. Advertisement and Other Third Parties: Advertising partners and other third parties may use cookies, scripts and/or web beacons to track visitor activities on this website in order to display advertisements and other useful information. Such tracking is done directly by the third parties through their own servers and is subject to their own privacy policies. This website has no access or control over these cookies, scripts and/or web beacons that may be used by third parties. Learn how to opt out of Google’s cookie usage. Links to Third Party Websites: We have included links on this website for your use and reference. We are not responsible for the privacy policies on these websites. You should be aware that the privacy policies of these websites may differ from our own. Security: The security of your personal information is important to us, but remember that no method of transmission over the Internet, or method of electronic storage, is 100% secure. While we strive to use commercially acceptable means to protect your personal information, we cannot guarantee its absolute security. Changes To This Privacy Policy: This Privacy Policy is effective and will remain in effect except with respect to any changes in its provisions in the future, which will be in effect immediately after being posted on this page. We reserve the right to update or change our Privacy Policy at any time and you should check this Privacy Policy periodically. If we make any material changes to this Privacy Policy, we will notify you either through the email address you have provided us, or by placing a prominent notice on our website. Contact Information: For any questions or concerns regarding the privacy policy, please contact us here. "
    }, {
    "id": 11,
    "url": "http://localhost:4000/tags.html",
    "title": "Tags",
    "body": "          Tags          {% for tag in site. tags %}     {{ tag[0] }}:           {% assign pages_list = tag[1] %}    {% for post in pages_list %}    {% if post. title != null %}     {% if group == null or group == post. group %}           {% include main-loop-card. html %}     {% endif %}    {% endif %}    {% endfor %}    {% assign pages_list = nil %}    {% assign group = nil %}    {% endfor %}                  {% include sidebar-featured. html %}          "
    }, {
    "id": 12,
    "url": "http://localhost:4000/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 13,
    "url": "http://localhost:4000/spread-divergence/",
    "title": "Training Models that have Zero Likelihood",
    "body": "2019/12/21 - A popular class of models in machine learning is the so-called generative model class with deterministic outputs. These are currently heavily used for example the generation of realistic images. If we represent an image with the variable , then these models generate an image by the following process:    Sample from a dimensional Gaussian (multivariate-normal) distribution.     Use this as the input to a deep neural network whose output is the image .  Typically the dimension of the latent variable is chosen to be much lower than the observation variable . This enables one to learn a low-dimensional representation of high-dimensional observed data. We can write this mathematically as a latent variable model producing a distribution over images , with and restricted to a deterministic distribution where we write to emphasise that the model depends on the parameters of the network. These models are powerful because they represent a very rich class of distributions (thanks to the highly non-linear neural network) but that are also easy to sample from (using the above procedure). So what’s the catch? Given a set of training images, , the challenge is to learn the parameters of the network .  Because the latent dimension is lower than the observation dimension , the model can only generate images in a dimensional manifold within the dimensional image space, as depicted in the figure for a latent dimension and observed dimension . That means that only images that lie on this manifold will have non-zero probability density value. For an image from the training dataset, unless it lies exactly on the manifold, the likelihood of this image will be zero. This means that typically the log likelihood of the dataset is not well defined and standard gradient based training of is not possible. This is a shame because (i) many standard training techniques are based on maximum likelihood and (ii) maximum likelihood is statistically efficient, meaning that no other training method can more accurately learn the model parameters . The inappropriateness of maximum likelihood as the training criterion for this class of models has inspired much recent work. For example the GAN objective and MMD objectives are well known approaches to training such models1. However, it is interesting to consider whether one can nevertheless modify the maximum likelihood criterion to make it applicable in this situation. The beauty of doing so is that we may then potentially use standard maximum likelihood style techniques (such as variational training approaches). The Spread Divergence: For concreteness, we consider the Kullback-Leibler Divergence divergence between distributions and Maximising the likelihood is equivalent to minimising the KL Divergence between the empirical data distribution and the model , since The fact that maximum likelihood training is not appropriate for deterministic output generative models is equivalent to the fact that the KL divergence (and its gradient) are not well defined for this class of model. More generally, for distributions and , the -Divergence is defined as where is a convex function with . However, this divergence may not be defined if the supports (regions of non-zero probability) of and are different, since then the ratio can cause a division by zero. This is the situation when trying to define the likelihood for data that is not on the low dimensional manifold of our model. The central issue we address therefore is how to convert a divergence which is not defined due to support mismatch into a well defined divergence. From and we define new distributions and that have the same support. We define distributions where `spreads’ the mass of and and is chosen such that and have the same support. Consider the extreme case of two delta distributions for which is not well defined. Using a Gaussian spread distribution with mean and variance ensures that and have common support . Then and and the KL divergence between the two becomes This divergence is well defined for all values of and . Indeed, this divergence has the convenient property that . If we consider to be our data distribution (a single datapoint at ) and  our model, we can now do a modified version of maximum likelihood training to fit to – instead of minimising , we minimise . Note that, in general, we must spread both distributions and for the divergence between the spreaded distributions to be zero to imply that the original distributions are the same. In the context of maximum likelihood learning, spreading only one of these distributions will in general result in a biased estimator of the underlying model. Stationary Spread Divergence: If we consider stationary spread distributions of the form , for `kernel’ function . It is straightforward to show that if the kernel has strictly positive Fourier Transform, then Interestingly, this condition on the kernel is equivalent to the condition on the kernel in the MMD framework2, which is an alternative way to define a divergence between distributions. It is easy to show that the Gaussian distribution has strictly positive Fourier Transform and thus defines a valid spread divergence. Another useful spread distribution with this property is the Laplace distribution. We discussed the above in the context of the KL divergence, but the argument also holds for the more general class of -divergences, broadening the class of training objectives now available to train deterministic output generative models. Machine Learning Applications: We now return to how to train models of the form and adjust the parameters to make the model fit the data distribution Since maximum likelihood is not (in general) available for this class of models, we instead consider minimising the spread KL divergence using Gaussian spread noise where the spreaded data distribution is The objective is then simply an expectation over the log likelihood , a quantity itself which is well defined since which is itself a standard generative model with a Gaussian output distribution.  For this we may now use a variational training approach to form a lower bound on the quantity . The final objective just then requires evaluating the expectation of this bound, which can be easily approximated by sampling from the spreaded data distribution Overall, this is therefore a simple modification of standard Variational Autoencoder (VAE) training in which there is an additional outer loop sampling from the spreaded data distribution. Our aim isn’t to produce the most impressive face sampler, but rather to show how one can make a fairly simple modification of the standard training algorithm to cope with deterministic outputs. In the figure below we show how we are able to fit a deep generative 4 layer convolutional network with deterministic output to the CelebA dataset of face images. Whilst this model cannot be trained using standard VAE approaches, using the spread divergence approach and sampling from the trained model gives images of the form below In our paper3 we apply this method to similarly how to overcome well known problems in training deterministic Independent Components Analysis models using only a simple modification of the standard training algorithm. We also discuss how to learn the spread distribution. Summary: A popular class of generative deep network models cannot be trained using standard classical machine learning approaches. However, by adding `noise’ to both the model and the data in an appropriate way, one can nevertheless define an appropriate objective that is amenable to standard machine learning training approaches. References:       S. Mohamed and B. Lakshminarayanan. Learning in Implicit Generative Models. arxiv. org/abs/1610. 03483, 2016.  &#8617;        A. Gretton et al. A Kernel Two-Sample Test. Journal of Machine Learning Research, 13. 2012.  &#8617;        M. Zhang, P. Hayes, T. Bird, R. Habib, D. Barber. Spread Divergence. arxiv. org/abs/1811. 08968, 2018.  &#8617;    "
    }, {
    "id": 14,
    "url": "http://localhost:4000/AICentre/",
    "title": "UCL AI Centre",
    "body": "2019/01/18 - The AI Centre carries out foundational research in AI. As we transition to a more automated society, the core aim of the Centre is to create new AI technologies and advise on the use of AI in science, industry and society. The Centre brings together researchers with a shared interest in fundamental challenges in Machine Vision, Machine Learning, Machine Reading, Machine Action, Interpretation and Knowledge Representation. The Centre takes inspiration from the vast array of applications across UCL and acts as the engine of methodological progress. This site contains postings of research. For more information, please see AI Centre Main Site. "
    }, {
    "id": 15,
    "url": "http://localhost:4000/gnmt/",
    "title": "Generative Neural Machine Translation",
    "body": "2018/09/12 - What’s wrong with current Machine Translation models?: Machine Learning models are still largely superficial – the models don’t really ‘understand’ the meaning of the sentences they are translating. If we want increasingly ‘intelligent’ machines, it’s important that models begin to incorporate more knowledge of the world.  One approach to achieve this is to require models to be good, not only at translation, but additional tasks, such as question answering.  A parallel direction is to encourage models to internally focus on the meaning of the sentence. This post summarises our approach to this latter direction, published at NIPS 20181. Learning meaningful representations of data: Latent variable models in natural language processing typically posit the following generative process for sentences:  A ‘hidden’ or ‘latent’ representation is randomly generated according to a prior distribution.  The sentence itself is then generated conditioned on this latent representation. Given a latent variable model and a sentence, the posterior distribution of the latent representation (i. e. the values of the representation that are likely to have generated that sentence) can be inferred. This posterior distribution can then be used for downstream tasks, e. g. the inferred representation could be used for answering questions about that sentence. Intuitively, the more information about the meaning of the sentence that the representation contains, the better it should be at performing at downstream tasks. Therefore, we would like to design a model which can use its latent representation to better represent the semantics of the text. Most latent variable models use one latent representation per sentence in the data set. The problem with this approach is that there are no guarantees that the representations will learn semantically meaningful information about the text. For example, consider the two sentences: “she walked across the road” and “the woman crossed the street” - a basic latent variable model does not know a priori that walking across a road and crossing a street are similar actions. Therefore, the typical model would not be able to guarantee that the latent representations of these two sentences are similar. Instead, if we were able to encode into the model that two sentences are semantically similar, we may be able to learn representations which better understand the meaning of the text. Unfortunately, large corpora of sentences with similar meanings in a single language are rare. However in the machine translation context, the same sentence expressed in different languages offers the potential to learn a latent variable model which better represents the sentence’s meaning. For example, a model which knows that the English sentence “the woman crossed the street” and the French sentence “la femme a traversé la rue” have the same meaning should be able to learn a representation with better semantic understanding. Generative Neural Machine Translation (GNMT): With Generative Neural Machine Translation (GNMT)1, we use a single shared latent representation to model the same sentence in multiple languages. The latent variable is a language agnostic representation of the sentence; by giving it the responsiblity for modelling the same sentence in multiple languages, it is encouraged to learn the semantic meaning. For each data point in a data set, typical latent variable architectures model the joint distribution of the latent representation and the observed sentence as: where are trainable parameters of the model.  Instead of modelling a single sentence per latent representation, GNMT uses a shared latent representation to model the same sentence both in the source and target languages. GNMT models the joint distribution of the latent representation, source sentence and target sentence as: This set up means that models the commonality between the source and target sentences, which is the semantic meaning. For full details on the neural networks used to model the distributions of the source and target , see 1. One may argue that it would be better if the target sentence were dependent only on the latent representation and not directly on the source sentence, giving the model – forcing the latent representation to be fully responsible for generating both the source and target sentence. However, we found that the generated translations weren’t sufficiently syntactically coherent. Training the model: We use the Stochastic Gradient Variational Bayes (SGVB)23 algorithm to train the model described above. SGVB introduces a ‘recognition’ model which acts as an approximation to the true but intractable posterior , thus forming the following lower bound on the log likelihood of the observed data: The model parameters and recognition parameters are then jointly learned by performing gradient ascent on this lower bound. Generating translations - the ‘banana trick’: Suppose the model has been trained, and then we are given a sentence in the source language () and asked to find a translation of that sentence. In this scenario, we want to find the most likely target sentence conditioned on the given source sentence. The natural objective is therefore: However this integral is intractable, and so we cannot perform this maximisation exactly. Instead, we perform approximate maximisation by iteratively refining a ‘guess’ for the target sentence. We first make a random guess for the target sentence, and then iterate between the following two steps:  Draw samples of the latent representation from the approximate posterior, using the source sentence and the latest guess for the target sentence.  Update the guess for the target sentence based on the latent representation samples from step 1. This update is done by choosing to maximise . Intuitively, this procedure computes the values of the latent representation that are likely to have generated both the source sentence and the latest guess for the target sentence. It then improves the guess based on those values of the latent variable. Mathematically, this iteratively increases a lower bound on until convergence and is an application of the Expectation Maximisation algorithm, here playing the role of parameters. Note: in our group we refer to this as the ‘banana trick’ because we are first aware of its usage in exercise 5. 7 in 4, discussing a ficitious protein sequence in bananas. Below, we show an example of a long sentence translated from English to French by GNMT. The long range coherence of the translation is a good indicator of the model’s ability to capture semantic information about the sentence within the latent representation. Source: Dans ce décret, il met en lumière les principales réalisations de la République d’Ouzbékistan dans le domaine de la protection et de la promotion des droits de l’homme et approuve le programme d’activités marquant le soixantième anniversaire de la déclaration universelle des droits de l’homme. Target: The decree highlights major achievements by the Republic of Uzbekistan in the field of protection and promotion of human rights and approves the programme of activities devoted to the sixtieth anniversary of the universal declaration of human rights. GNMT: In this decree, it highlights the main achievements of the Republic of Uzbekistan on the protection and promotion of human rights and approves the activities of the sixtieth anniversary of the universal declaration of human rights. Dealing with missing words: Because GNMT’s latent representation captures information about the meaning of the sentence rather than just the syntax, it is able to produce good translations even when there are missing words in the source sentence. The procedure for generating translations is similar to that described above – however in this scenario we also have to refine a guess for the missing words in the source sentence. We first make random guesses for the missing words in the source sentence and for the target sentence, and then iterate between the following three steps:  Draw samples of the latent representation from the approximate posterior, using the latest guesses for the source and target sentences.  Update the guess for the source sentence based on the latent representation samples from step 1. This update is done by choosing to maximise .  Update the guess for the target sentence based on the latent representation samples from step 1 and on the updated guess for the source sentence from step 2. This update is done by choosing to maximise . Below is an example of a sentence translated from Spanish to English, where the struck through words in the source sentence are considered missing. Using its latent representation, the model does remarkably well at imputing what the missing words may be and translating them accordingly. Source: Expresando su satisfacción por la asistencia que han prestado a los territorios no autónomos algunos organismos especializados y otras organizaciones del sistema de las naciones unidas, especialmente el programa de las naciones unidas para el desarrollo. Target: Welcoming the assistance extended to non-self-governing territories by certain specialized agencies and other organizations of the United Nations system, in particular the United Nations development programme. GNMT: Expressing its gratitude for the assistance given to non-self-governing territories by some specialized agencies and other organizations of the United Nations system, in particular from the development programmes of the United Nations. Cross-language parameter sharing: With the architecture described above, if we wanted to translate between, say, English (EN), Spanish (ES) and French (FR), we would have to train 6 separate models for EN → ES, ES → EN, EN → FR, etc. However because all three of these languages share somewhat similar structures, we may not lose much performance by sharing parameters. We therefore add two indicator variables to the model, one for the input language () and another for the output language (). By doing this, we only have to train a single model to translate between three languages, instead of having 6 separate models. The joint distribution of the latent representation, source sentence and target sentence becomes: We refer to this version of the model as GNMT-Multi. Overfitting is a phenomenon whereby a model is too closely fit to a particular set of data points. In machine translation, this often occurs when there aren’t enough paired sentences for the model to learn from. However, the cross language parameter sharing used for GNMT-Multi helps to mitigate this issue. This is because 6 separate models are essentially condensed into a single model, meaning that there aren’t enough parameters to allow the model to memorise the training data. Below, we plot the BLEU scores comparing GNMT-Multi against 6 separate GNMT models, trained with only 400,000 pairs of translated sentences. BLEU is a measure of how well the generated translations match the true target sentences; higher is better. Clearly GNMT-Multi with a limited amount of available training data performs significantly better than each of the 6 separate GNMT models.  When there is a large amount of training data available, we find that there is very little difference in the performance of GNMT and GNMT-Multi. Below, we plot the BLEU scores for the models trained with 4,000,000 sentence pairs; we find that there is no degradation in performance due to sharing parameters across languages! Semi-supervised learning: Suppose, as in the previous section, that we only have access to a limited number of paired sentences, but that we now have available lots of untranslated sentences in each language. To learn from untranslated sentences, we can set the input language and output language to the same value, so that the model learns to reconstruct the sentence instead of translating it. Intuitively, this should further help the model to learn the structure and style of each language and thus produce more coherent translations at test time. We refer to this version of the model as GNMT-Multi-SSL. Below we plot the BLEU scores of GNMT-Multi-SSL, GNMT-Multi and the 6 separate GNMT models. They are trained first with 400,000 then with 4,000,000 pairs of translated sentences. In both cases, they are also trained with approximately 20,900,000 untranslated English sentences, 2,700,000 untranslated Spanish sentences and 4,500,000 untranslated French sentences. GNMT-Multi-SSL clearly helps to mitigate overfitting when there are limited paired sentences available. In fact, GNMT-Multi-SSL trained with only 400,000 paired sentences performs about as well as each of the 6 separate GNMT models trained with 4,000,000 sentences! GNMT-Multi-SSL also produces higher BLEU scores even when there is lots of paired data; this verifies our intuition that adding monolingual data helps the model to develop a better understanding of each language individually, and output more coherent sentences accordingly.  Summary: We introduce Generative Neural Machine Translation (GNMT), which is a latent variable model that uses sentences with the same meaning in multiple languages to learn representations which better understand the semantics of the text. It can be used to translate a source sentence by iteratively refining a guess for the target sentence and updating the latent representation accordingly. Because it captures the meaning of the sentence, GNMT is particularly effective at producing translations when there are missing words in the source sentence. We also introduce GNMT-Multi, which is a single unified model (instead of one per language pair) to mitigate overfitting when there is limited paired data available. Finally, we leverage large amounts of untranslated sentences to help the model to further learn the structure and style of each language and produce more coherent translations. References:       H. Shah and D. Barber. Generative Neural Machine Translation. In Advances in Neural Information Processing Systems, 2018.  &#8617; &#8617;2 &#8617;3        D. Kingma and M. Welling. Auto-Encoding Variational Bayes. In International Conference on Learning Representations, 2014.  &#8617;        D. Rezende, et al. Stochastic Backpropagation and Approximate Inference in Deep Generative Models. In Proceedings of the 31st International Conference on Machine Learning, PMLR 32, pages 1278–1286, 2014.  &#8617;        D. Barber. Bayesian Reasoning and Machine Learning. Cambridge University Press, 2016.  &#8617;    "
    }, {
    "id": 16,
    "url": "http://localhost:4000/exit/",
    "title": "Learning From Scratch by Thinking Fast and Slow with Deep Learning and Tree Search",
    "body": "2017/11/07 - According to dual process theory human reasoning consists of two different kinds of thinking. System 1 is a fast, unconscious and automatic mode of thought, also known as intuition. System 2 is a slow, conscious, explicit and rule-based mode of reasoning that is believed to be an evolutionarily recent process. image credit When learning to complete a challenging planning task, such as playing a board game, humans exploit both processes: strong intuitions allow for more effective analytic reasoning by rapidly selecting interesting lines of play for consideration. Repeated deep study gradually improves intuitions. Stronger intuitions feedback to stronger analysis, creating a closed learning loop. In other words, humans learn by thinking fast and slow1. What’s wrong with current Deep RL?: In current Deep Reinforcement Learning (RL) algorithms such as Policy Gradients2 and DQN3, neural networks make action selections with no lookahead; this is analogous to System 1. Unlike human intuition, their training does not benefit from a ‘System 2’ to suggest strong policies. A criticism of some AI algorithms such as AlphaGo4 is that they use a database of human expert play4.  In the initial phase of training the RL agent mimics the moves of a human expert – only after this initial phase does it begin to learn potentially more powerful super-human play. This is somewhat unsatisfactory since the resulting algorithm may be heavily biased toward a human style of playing, blind to potentially more powerful lines of play. Whilst, in areas such as game playing, it may be natural to assume that there will be a database of human expert play available, in other settings in which we wish to train an AI machine, no such database may be available. Therefore, showing how to train a state-of-the-art board game player ex nihilo is a major challenge for AI. Expert Iteration (ExIt): Expert Iteration5 (ExIt) is a general framework for learning that we introduced in May 2017 and can result in powerful AI machines, without needing to mimic human strategies.  ExIt can be viewed as an extension of Imitation Learning (IL) methods to domains where the best known experts are unable to achieve satisfactory performance. In standard IL an apprentice is trained to imitate the behaviour of an expert.  In ExIt, we extend this to an iterative learning process.  Between each iteration, we perform an Expert Improvement step, where we bootstrap the (fast) apprentice policy to increase the performance of the (comparatively slow) expert. To give some intuition around this idea, consider playing a board game such as chess. Here the expert is analogous to chess player playing on slow time controls (having lots of time to decide on her move), and the apprentice is playing on blitz time controls (having little time to decide which move to make). During independent study, the player considers multiple possible moves from a position, thinking deeply (and slowly) about each possible move. She discovers which moves are successful and which are not in this position. When she encounters a similar board state in the future, her study will have given her an intuitive understanding of what moves are likely to be good, allowing her to play well, even under blitz time controls. Her intuition is imitating the strong play she calculated via deep thinking. Humans do not become become excellent chess players by only playing blitz matches, deeper study is an essential part of the learning process. For an AI game playing machine, this imitation could be achieved, for example, by fitting a neural network to the move made by another `machine expert’ from a game position.  The apprentice learns a fast policy that is able to quickly imitate the play of the expert on the moves seen so far.  A key point here is that, assuming that there is structure underlying the game, Machine Learning enables the apprentice to generalise their intuition to take quick decisions on positions not previously seen. That is, the apprentice isn’t just a creating a look-up-table of moves made by the human from a fixed database of positions. The neural network thus plays the role of both generalising and imitating the play of the expert. Now that the apprentice has learned a fast imitation of the expert (on the moves seen so far), it can try to be of use to the expert. When the expert now wishes to make a move, a small set of candidate moves are suggested very quickly by the apprentice which the expert can then consider in depth, possibly also guided during this slow thought process by other quick insights from the apprentice. At the end of this phase, the expert will have made a set of apprentice-aided moves, with each move being typically much stronger than either the apprentice or expert could have made alone. The above process now repeats, with the apprentice retraining on the moves suggested by the expert. This completes one full iteration of the learning phase and we iterate this process until the apprentice converges. From a Dual Process perspective, the Imitation Learning step is analogous to a human improving their intuition for the task by studying example problems, while the Expert Improvement step is analogous to a human using their improved intuition to guide future analysis. Tree Search and Deep Learning: Exit is a general strategy for learning and the apprentice and expert can be specified in a variety of ways. In board games Monte Carlo Tree Search (MCTS) is a strong playing strategy6 and is a natural candidate to play the role of the expert.  Deep Learning has been shown to be a successful method to imitate the play of strong players4 which we therefore use as the apprentice. At the Expert Improvement phase we use the apprentice to direct the MCTS algorithm toward promising moves, effectively reducing the game tree search breadth and depth. In this way, we bootstrap the knowledge acquired by Imitation Learning back into the planning algorithm. The board game Hex: Hex is a classic two-player board game played on a hexagonal grid. The players, denoted by colours black and white, alternate placing stones of their colour in empty cells. The black player wins if there is a sequence of adjacent black stones connecting the North edge of the board to the South edge. White wins if he achieves a sequence of adjacent white stones running from the West edge to the East edge. An example game on a Hex board. The above represents play on a board, with white winning (reproduced from 7).  Hex has deep strategy, making it challenging for machines to play and its large action set and connection-based rules means it shares similar challenges for AI to Go. Compared to Go, however, the rules are simpler and there can be no draws. Because the rules of Hex are so simple, the game is relatively amenable to mathematical analysis (compared for example to Go) and the current best machine player MoHex7 uses a combination of MCTS and smart mathematical insights.  MoHex has won every Computer Games Olympiad Hex tournament since 2009. It is noteworthy, that MoHex uses a rollout policy trained on datasets of human expert play. We wanted to see if we can use our ExIt training strategy to learn an AI player than can outperform MoHex, without using any game-specific knowledge or human example play (beside the rules of the game). To do this, our expert is a MCTS player that is guided by the apprentice neural network.  Our neural network is a form of deep convolutional network with two output policies – ones for black play and one for white (see 5 for details). Expert Improvement is achieved by using the modified MCTS formula8 Here is the state of the Hex board, is a possible action (i. e. move) from . The term represents the classical Upper Confidence Bound for Trees6 used in MCTS. The additional term helps the neural network apprentice guide the search to more promising moves. In this term is the policy (suggested relative strength of each possible action from the board state ) of the apprentice and the number of visits currently made by the search algorithm through state and taking action ; is an empirically chosen weighting factor that balances the slow thinking of the expert with the fast intuition of the apprentice. Through the additional term, the neural network apprentice guides the search to more promising moves, and rejects weak moves more quickly. To generate the data for training the apprentice (during each Imitation Learning phase), the batch approach generates data afresh, discarding all data from previous iterations. We also consider a online version in which we instead keep a running buffer of the most recent moves generated; we further consider an online version that retains all data, but with exponentially more data from more recent experts (which correspond to the strongest play).  A comparison of these different approaches is given below in which we compare the strength (measured in terms of the ELO score) of each learned policy network against a measure of training time.  We also show the result of using a more traditional Reinforcement Learning approach in which a policy is learned only through self play (i. e. no MCTS). This is essentially the method used within AlphaGo4 to train their policy network. The figure shows that the ExIt training approach is considerably more effective than more classical approaches. It is worth noting that in this example training has not yet fully converged and the apprentice would be expected to improve in ability further given additional training time. In our paper5 we include an additional mechanism to improve play, namely a value network that approximates the probability that the apprentice (alone) would win the game from position . Both the policy and value network are then used in combination to help guide the final apprentice-aided MCTS player. The policy network and value networks guide the final MCTS player using an equation similar to \eqref{eq:uct}, but modified to include the apprentice’s value of the state (see 5 for details). Our final MCTS player outperforms the best known machine Hex player, MoHex, beating it in 75% of games played on a board. These results are even more remarkable considering that training has not fully converged. A couple of examples of game-play of our ExIt trained player versus the state-of-the-art MoHex player are shown below9. We contrast the play of each algorithm when started at the same position. See the paper5 for more examples. ExIt (black) versus MoHex (white) MoHex (black) versus ExIt (white) Why does ExIt work so well?: Imitation Learning is generally appreciated to be easier than Reinforcement Learning, and this partly explains why ExIt is more successful than model-free methods like REINFORCE. Furthermore, for MCTS to recommend a move, it must be unable to find any weakness with its search. Effectively, therefore, a move played by MCTS is good against a large selection of possible opponents. In contrast, in regular self play (in which the opponent move is made by the network playing as the opposite colour), moves are recommended if they beat only this single opponent under consideration. This is, we believe, a key insight into why ExIt works well (when using MCTS as the expert) — the apprentice effectively learns to play well against many opponents. Relation to AlphaGo Zero: AlphaGo Zero10 (developed independently of our work11) also implements an ExIt style algorithm and shows that it is possible to achieve state-of-the-art performance in Go without the use of human expert play. A detailed comparison of the approaches is given in our paper5. Summary: Expert Iteration is a new Reinforcement Learning algorithm, motivated by the dual process theory of human thought. ExIt decomposes the Reinforcement Learning into the separate subproblems of generalisation and planning. Planning is performed on a case-by-case basis, and only once a strong plan is found is the resultant policy generalised. This allows for long-term planning and results in faster learning and state-of-the-art final performance, particularly for challenging problems. This training strategy is powerful enough to learn state-of-the-art board game AI players without requiring any examples of expert human play. References:       D. Kahneman. Thinking, Fast and Slow. Macmillan, 2011.  &#8617;        R. J. Williams. Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning. Machine Learning, 8(3-4):229–256, 1992.  &#8617;        V. Mnih et al. Human-Level Control through Deep Reinforcement Learning. Nature, 518(7540):529–533, 2015.  &#8617;        D. Silver et al. Mastering the Game of Go with Deep Neural Networks and Tree Search. Nature, 529(7587):484–489, 2016.  &#8617; &#8617;2 &#8617;3 &#8617;4        T. Anthony, Z. Tian and D. Barber. Thinking Fast and Slow with Deep Learning and Tree Search, Neural Information Processing Systems (NIPS 2017). In Press.  &#8617; &#8617;2 &#8617;3 &#8617;4 &#8617;5 &#8617;6        L. Kocsis and C. Szepesvári. Bandit Based Monte-Carlo Planning. In European Conference on Machine Learning, pages 282–293. Springer, 2006.  &#8617; &#8617;2        S. -C. Huang, B. Arneson, R. Hayward, M. Müller, and J. Pawlewicz. MoHex 2. 0: A Pattern-Based MCTS Hex Player. In International Conference on Computers and Games, pages 60–71. Springer, 2013.  &#8617; &#8617;2        S. Gelly and D. Silver. Combining Online and Offline Knowledge in UCT. In Proceedings of the 24th International Conference on Machine learning, pages 273–280. ACM, 2007.  &#8617;        Thanks to Ryan Hayward for providing a tool to draw Hex positions.  &#8617;        D. Silver, et al.  Mastering the game of Go without human knowledge. Nature 550:354–359, October 2017.  &#8617;        T. Anthony, Z. Tian and D. Barber. Thinking Fast and Slow with Deep Learning and Tree Search. arXiv CoRR:abs/1705. 08439, May 2017.  &#8617;    "
    }, {
    "id": 17,
    "url": "http://localhost:4000/gauss-newton/",
    "title": "Some modest insights into the error surface of Neural Nets",
    "body": "2017/07/30 - Did you know that feedforward Neural Nets (with piecewise linear transfer functions) have no smooth local maxima? In our recent ICML paper Practical Gauss-Newton Optimisation for Deep Learning) we discuss a second order method that can be applied successfully to accelerate training of Neural Networks. However, here I want to discuss some of the fairly straightforward, but perhaps interesting, insights into the geometry of the error surface that that work gives.  Feedforward Neural Networks: In our description, a feedforward NN takes an input vector and produces a vector on the final layer. We write to be the vector of pre-activation values for layer and to denote the vector of activation values after passing through the transfer function . Starting with setting  to the input , a feedforward NN is defined by the recursion where is the weight matrix of layer (we use a sub or superscript wherever most convenient) and the activation vector is given by We define a loss between the final output layer and a desired training output . For example, we might use a squared loss where the loss is summed over all elements of the vector.  For a training dataset the total error function is the summed loss over individual training points where represents the stacked vector of all parameters of the network. For simplicity we will write for the error for a single generic datapoint. The Gradient: For training a NN, a key quantity is the gradient of the error We use this for example in gradient descent training algorithms. An important issue is how to compute the gradient efficiently. Thanks to the layered structure of the network, it’s intuitive that there is an efficient scheme (backprop which is a special case of Reverse Mode AutoDiff) that propagates information from layer to layer. The Hessian: One aspect of the structure of the error surface is the local curvature, defined by the Hessian matrix with elements The Hessian matrix itself is typically very large. To make this more manageable, we’ll focus here on the Hessian of the parameters of a given layer .  That is The Hessians then form the diagonal block matrices of the full Hessian . A recursion for the Hessian: Similar to the gradient, it’s perhaps intuitive that a recursion exists to calculate this layerwise Hessian.  Starting from and differentiating again we obtain where we define the pre-activation Hessian for layer as We show in Practical Gauss-Newton Optimisation for Deep Learning that one can derive a simple backwards recursion for this pre-activation Hessian (the recursion is for a single datapoint – the total Hessian is a sum over the individual datapoint Hessians): where we define the diagonal matrices and Here is the first derivative of the transfer function and is the second derivative. The recursion is initialised with which depends on the objective and is easily calculated for the usual loss functions. For example, for the square loss we have , namely the identity matrix. We use this recursion in our paper to build an approximate Gauss-Newton optimisation method. Consequences: Piecewise linear transfer functions, such as the ReLU are currently popular due to both their speed of evaluation (compared to more traditional transfer functions such as ) and also the empirical observation that, under gradient based training, they tend to get trapped less often in local optima. Note that if the transfer functions are piecewise linear, this does not necessarily mean that the objective will be piecewise linear (since the loss is usually itself not piecewise linear). For a piecewise linear transfer function, apart from the `nodes’ where the linear sections meet, the function is differentiable and has zero second derivative, . This means that the matrices in the above Hessian recursion will be zero (away from nodes). For many common loss functions, such as squared loss (for regression) and cross entropy loss (for classification) the Hessian is Positive Semi-Definite (PSD). Note that, according to \eqref{eq:recursion}, for transfer functions that contain zero gradient points then the Hessian can have lower rank than , reducing the curvature information propagating back from layers close to the output towards layers closer to the input. This has the effect of creating flat plateaus in the surface and makes gradient based training potentially more problematic. Conversely, provided the gradient of the transfer function is never zero , then according to \eqref{eq:recursion} each layer pre-activation Hessian is Positive Definite, helping preserve the propagation of surface curvature back through the network. Structure within a layer: For such loss functions, it follows that the pre-activation Hessian for all layers is PSD as well (away from nodes).  It immediately follows from \eqref{eq:H} that the Hessian for each layer is PSD.  This means that, if we fix all the parameters of the network, and vary only the parameters in a layer , then the objective can exhibit no smooth local maxima or smooth saddle points.  Note that this does not imply that the objective is convex everywhere with respect to as the surface will contain ridges corresponding to the non-differentiable nodes. No differentiable local maxima: The trace of the full Hessian is the sum of the traces of each of the layerwise blocks . Since (as usual away from nodes) by the above argument each matrix is PSD, it follows that the trace of the full Hessian is non-negative.  This means that it is not possible for all eigenvalues of the Hessian to be simultaneously negative, with the immediate consequence that feedforward networks (with piecewise linear transfer functions) have no differentiable local maxima. The picture below illustrates the kind of situtation therefore that can happen in terms of local maxima: whereas the image below depicts the kind of smooth local maxima that cannot happen: Visualisation for a simple two layer net: We consider a simple network with two layers, ReLU transfer functions and square loss error. The network thus has two weight matrices and .  Below we choose two fixed matrices and and parameterise the weight matrix as a function of two scalars and , so that .  As we vary and we then plot the objective function , keeping all other parameters of the network fixed. As we can see the surface contains no local differentiable local maxima as we vary the parameters in the layer.  Below we show an analogous plot for varying the parameters of the second layer weights , which has the same predicted property that there are no differentiable local maxima.  Finally, below we plot using and , showing how the objective function changes as we simultaneously change the parameters in different layers. As we can see, there are no differentiable maxima.  SummaryA simple consequence of using piecewise linear transfer functions and a convex loss, is that feedforward networks cannot have any differentiable maxima (or saddle points) as parameters are varied within a layer. Furthermore, the objective cannot contain any differentiable maxima, even as we vary parameters across layers. Note that the objective though can (and empirically does) have smooth saddle points as one varies parameters and across different layers. It’s unclear how practically significant these modest insights are. However, they do potentially partially support the use of piecewise linear transfer functions (particularly those with no zero gradient regions) since for such transfer functions gradient based training algorithms cannot easily dawdle on local maxima (anywhere), or idle around saddle points (within a layer) since such regions correspond to sharp slopes in the objective. These results are part of a more detailed study of second order methods for optimisation in feedforward Neural Nets which will appear in ICML 2017. "
    }, {
    "id": 18,
    "url": "http://localhost:4000/var-opt/",
    "title": "Evolutionary Optimization as a Variational Method",
    "body": "2017/04/03 -  Variational Optimization is based on the bound That is, the minimum of a collection of values is always less than their average.  By defining instead of minimising with respect to , we can minimise the upper bound with respect to . Provided the distribution is rich enough, this will be equivalent to minimising . The gradient of the upper bound is then given by which is reminiscent of the REINFORCE (Williams 1992) policy gradient approach in Reinforcement Learning. In the original VO report and paper this idea was used to form a differentiable upper bound for non-differentiable and also discrete . Sampling Approximation: There is an interesting connection to evolutionary computation (more precisely Estimation of Distribution Algorithms) if the expectation with respect to is performed using sampling. In this case one can draw samples from and form an unbiased approximation to the upper bound gradient The “evolutionary” connection is that the samples can be thought of as “particles” or “swarm members” that are used to estimate the gradient. Based on the approximate gradient, simple Stochastic Gradient Descent (SGD) would then perform the parameter update (for learning rate ) The “swarm” then disperses and draws a new set of members from and the process repeats. A special case of VO is to use a Gaussian so that (for the scalar case – the multivariate setting follows similarly) Then the gradient of this upper bound is given by By changing variable this is equivalent to Fixing and using samples, we show below the trajectory (for 150 steps of SGD with fixed learning rate ) of based on Stochastic VO and compare this to the underlying function (which in this case is a simple quadratic).  Note that we only plot below the parameter trajectory (each red dot represents a parameter , with the initial parameter in the bottom right) and not the samples from .  As we see, despite the noisy gradient estimate, the parameter values move toward the minimum of the objective .  The matlab code is available if you’d like to play with this.  One can also consider the bound as a function of both the mean and variance : and minimise the bound with respect to both and (which we will parameterise using to ensure a positive variance). More generally, one can consider parameterising the Gaussian covariance matrix for example using factor analysis and minimsing the bound with respect to the factor loadings. Using a Gaussian with covariance and performing gradient descent on both and , for the same objective function, learning rate  and initial , we obtain the trajectory below for  As we can see, by learning , the trajectory is much less noisy and more quickly homes in on the optimum.  The trajectory of the learned standard deviation is given below, showing how the variance reduces as we home in on the optimum.  In the context of more general optimisation problems (such as in deep learning and reinforcement learning), VO is potentially interesting since the sampling process can be distributed across different machines. Gradient Approximation by Gaussian Perturbation: Ferenc Huszar‏ has a nice post Evolution Strategies: Almost Embarrassingly Parallel Optimization summarising recent work by Salimans etal on Evolution Strategies as a Scalable Alternative to Reinforcement Learning. The aim is to minimise a function by using gradient based approaches, without explicitly calculating the gradient. The first observation is that the gradient can be approximated by considering the Taylor expansion Multiplying both sides by Finally, taking the expectation with respect to drawn from a Gaussian distribution with zero mean and variance we have Hence, we have the approximation Based on the above discussion of VO, and comparing equations (1) and (2) we see that this Gaussian perturbation approach is related to VO in which we use a Gaussian , with the understanding that in the VO case the optimisation is over rather than .  An advantage of the VO approach, however, is that it provides a principled way to adjust parameters such as the variance (based on minimising the upper bound). Whilst this was derived for the scalar setting, the vector derivative is obtained by applying the same method, where the vector is drawn from the zero mean multivariate Gaussian with covariance for identity matrix . Efficient Communication: A key insight in Evolution Strategies as a Scalable Alternative to Reinforcement Learning is that the sampling process can be distributed across multiple machines, so that where is a vector sample and is the sample index. Each machine can then calculate . The Stochastic Gradient parameter update with learning rate is Provided each machine also knows the random seed used to generate the of each other machine, it therefore knows what all the are (by sampling according to the known seeds) and can thus calculate based on only the scalar values calculated by each machine. The basic point here is that, thanks to seed sharing, there is no requirement to send the vectors between the machines (only the scalar values need be sent), keeping the transmission costs very low. Based on the insight that the Parallel Gaussian Perturbation approach is a special case of VO, it would be natural to apply VO using seed sharing to efficiently parallelise the sampling. This has the benefit that other parameters such as the variance can also be efficiently communicated, potentially significantly speeding up convergence. "
    }, {
    "id": 19,
    "url": "http://localhost:4000/large-class/",
    "title": "Training with a large number of classes",
    "body": "2017/03/15 - In machine learning we often face the issue of a very large number of classes in a classification problem. This causes a bottleneck in the computation. There’s though a simple and effective way to deal with this. Probabilistic Classification: In areas like Natural Language Processing (NLP) a common task is to predict the next word in sequence (like in preditictive text on a smartphone or in learning word embeddings).  For input and class label , the probability of predicting class is where is some defined function with parameters . For example, , where is a parameter vector for class and is the vector input.  The normalising term is The task is then to adjust the parameters to maximise the probability of the correct class for each of the training points. However, if there are words in the dictionary, this means calculating the normalisation for each datapoint is going to be expensive.  There have been a variety of approaches suggested over the years to make computationally efficient approximations, many based on importance sampling. Why plain Importance Sampling doesn’t work: A standard approach to approximating is to use where is an importance distribution over all classes.  We can then form an approximation by sampling from a small number of classes to form a sample bag and using The problem with this approach is that it results in a potentially catastrophic under-estimate of .  If the classifier is working well, we want that is much higher than for any incorrect class .  Hence, unless the importance sample bag includes class , then the normalisation approximation will miss this significant mass and the probability approximation will be wildly inaccurate, see figure (a) below.  This is the source of the historically well-documented instabilities in training large-scale classifiers. Making Importance Sampling work: However, there is an easy fix for this – simply ensure that includes the correct class .  On the left above we show for classes the ratio on the -axis against its approximation  on the -axis. Each dot represents a different randomly drawn set of values. Red, green and blue represent 10, 20 and 50 importance samples respectively. The ideal estimation would be such that all points are along the line .  Note the vertical scale – these values are supposed to be probabilities and lie between 0 and 1.  Even as we increase the number of importance samples, this remains a wildly incorrect estimation of the probability. On the right above we show the same probability estimate but now simply also include the correct class in the set . The vertical scale is now sensible and the estimated probabiliy is close to the true value. Deep Learning Recurrent NLP models: We applied this method to learning word embeddings for a deeprecurrent network.  The training objective was standard maximumlikelihood, but with the normalisation approximation above. Below weplot the exact log likelihood (-axis) against the optimisationgradient ascent iteration (-axis). We also plot the exact loglikelihood for some alternative training approaches. As wesee, standard Importance Sampling becomes unstable as learningprogresses. However our simple modification stabilizes learning and iscompetitive against a range of alternatives including NoiseContrastive Estimation, Ranking approaches, Negative Sampling andBlackOut.  This is so simple and works so well that we use this in all our NLP deep learning training experiments. This forms the basis for our paper Complementary Sum Sampling for Likelihood Approximation in Large Scale Classification which will appear in AISTATS 2017. "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});


    
function lunr_search(term) {
    $('#lunrsearchresults').show( 1000 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-secondary btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
</script>
<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>




<form class="bd-search hidden-sm-down" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
<input type="text" class="form-control text-small"  id="lunrsearch" name="q" value="" placeholder="Type keyword and enter..."> 
</form>
            </ul>
        </div>
    </div>
    </nav>

    <!-- Search Results -->
    <div id="lunrsearchresults">
        <ul class="mb-0"></ul>
    </div>

    <!-- Content -->
    <main role="main" class="site-content">
        <div class="container">
<h3 class="font-weight-bold spanborder"><span>Privacy Policy</span></h3>
<div class="page-content">
<p>“UCL AI Centre Posts” takes your privacy seriously. To better protect your privacy we provide this privacy policy notice explaining the way your personal information is collected and used.</p>

<h4 id="collection-of-routine-information">Collection of Routine Information</h4>

<p>This website track basic information about their visitors. This information includes, but is not limited to, IP addresses, browser details, timestamps and referring pages. None of this information can personally identify specific visitor to this website. The information is tracked for routine administration and maintenance purposes.</p>

<h4 id="cookies">Cookies</h4>

<p>Where necessary, this website uses cookies to store information about a visitor’s preferences and history in order to better serve the visitor and/or present the visitor with customized content.</p>

<h4 id="advertisement-and-other-third-parties">Advertisement and Other Third Parties</h4>

<p>Advertising partners and other third parties may use cookies, scripts and/or web beacons to track visitor activities on this website in order to display advertisements and other useful information. Such tracking is done directly by the third parties through their own servers and is subject to their own privacy policies. This website has no access or control over these cookies, scripts and/or web beacons that may be used by third parties. Learn how to <a href="http://www.google.com/privacy_ads.html">opt out of Google’s cookie usage</a>.</p>

<h4 id="links-to-third-party-websites">Links to Third Party Websites</h4>

<p>We have included links on this website for your use and reference. We are not responsible for the privacy policies on these websites. You should be aware that the privacy policies of these websites may differ from our own.</p>

<h4 id="security">Security</h4>

<p>The security of your personal information is important to us, but remember that no method of transmission over the Internet, or method of electronic storage, is 100% secure. While we strive to use commercially acceptable means to protect your personal information, we cannot guarantee its absolute security.</p>

<h4 id="changes-to-this-privacy-policy">Changes To This Privacy Policy</h4>

<p>This Privacy Policy is effective and will remain in effect except with respect to any changes in its provisions in the future, which will be in effect immediately after being posted on this page.</p>

<p>We reserve the right to update or change our Privacy Policy at any time and you should check this Privacy Policy periodically. If we make any material changes to this Privacy Policy, we will notify you either through the email address you have provided us, or by placing a prominent notice on our website.</p>

<h4 id="contact-information">Contact Information</h4>

<p>For any questions or concerns regarding the privacy policy, please <a href="/contact.html">contact us here</a>.</p>

<!-- Comments -->

</div>
</div>
    </main>


    <!-- Scripts: popper, bootstrap, theme, lunr -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

    <script src="/assets/js/theme.js"></script>


    <!-- Footer -->
    <footer class="bg-white border-top p-3 text-muted small">
        <div class="container">
        <div class="row align-items-center justify-content-between">
            <div>
                <span class="navbar-brand mr-2 mb-0"><strong>UCL AI Centre Posts</strong></span>
                <span>Copyright © <script>document.write(new Date().getFullYear())</script>.</span>
            </div>
            <div>
                Made with <a target="_blank" class="text-dark font-weight-bold" href="https://www.wowthemes.net/mundana-jekyll-theme/"> Mundana Jekyll Theme </a> by <a class="text-dark" target="_blank" href="https://www.wowthemes.net">WowThemes</a>.
            </div>
        </div>
        </div>
    </footer>

    <!-- All this area goes before </body> closing tag --> 


</body>

</html>
